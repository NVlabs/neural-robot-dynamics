# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys, os
base_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../'))
sys.path.append(base_dir)

from typing import List, Dict, Union
import numpy as np
from tqdm import trange

import warp as wp

from envs.neural_environment import NeuralEnvironment
from generate.simulation_sampler import \
    UniformSampler, \
    compute_contact_points_0_world, compute_contact_points_1
from generate.trajectory_sampler import TrajectorySampler

import torch

"""
Trajectory-mode dataset generator for Pendulum env.
In Pendulum, we use abstract mode for contact sampling, where we directly sample 
contact information instead of using the collision detection in the env.
The contact information is generated by randomly sampling a ground plane.
The ground plane is randomized for each trajectory and keeps fixed during the trajectory.
"""
class TrajectorySamplerPendulum(TrajectorySampler):
    """Data generator that samples random trajectories [(states, controls, next_states)]."""

    def __init__(
        self,
        env: NeuralEnvironment,
        joint_q_min: Union[float, np.ndarray],
        joint_q_max: Union[float, np.ndarray],
        joint_qd_min: Union[float, np.ndarray],
        joint_qd_max: Union[float, np.ndarray],
        joint_act_scale: float,
        contact_prob: float = 0.,
        sampler=UniformSampler()
    ):
        super().__init__(
            env, 
            joint_q_min, joint_q_max, 
            joint_qd_min, joint_qd_max,
            joint_act_scale,
            contact_prob,
            sampler
        )

    def sample_trajectories_abstract_mode(
        self, 
        num_transitions: int, 
        trajectory_length: int, 
        passive: bool = False,
        render: bool = False,
        export_video: bool = False,
        export_video_path: str = None
    ) -> List[Dict]:

        rollout_batches = {
            'gravity_dir': [],
            'root_body_q': [],
            'states': [],
            'contacts': {
                'contact_normals': [],
                'contact_depths': [],
                'contact_points_0': [],
                'contact_points_1': [],
                'contact_thicknesses': []
            },
            'joint_acts': [],
            'next_states': []
        }
        
        progress = trange(
            0, num_transitions, 
            self.num_envs * trajectory_length, 
            desc="Sampling state transitions"
        )
        
        # allocate round-wise buffers
        initial_states = torch.empty(
            self.num_envs,
            self.state_dim,
            dtype=torch.float32,
            device=self.torch_device)
        states = torch.empty(
            trajectory_length, 
            self.num_envs,
            self.state_dim,
            dtype=torch.float32,
            device=self.torch_device)
        next_states = torch.empty(
            trajectory_length, 
            self.num_envs,
            self.state_dim,
            dtype=torch.float32,
            device=self.torch_device)
        joint_acts = torch.empty(
            trajectory_length, 
            self.num_envs,
            self.joint_act_dim,
            dtype=torch.float32,
            device=self.torch_device)
        root_body_q = torch.empty(
            trajectory_length,
            self.num_envs,
            7,
            dtype=torch.float32,
            device=self.torch_device)
        gravity_dir = torch.empty(
            trajectory_length, 
            self.num_envs,
            3,
            dtype=torch.float32,
            device=self.torch_device)
        gravity_dir[:, :, self.env.model.up_axis] = -1.0

        num_contacts_per_env = self.env.abstract_contacts.num_contacts_per_env
        
        contact_normals = torch.empty(
            trajectory_length,
            self.num_envs,
            num_contacts_per_env,
            3,
            dtype=torch.float32,
            device=self.torch_device
        )
        
        contact_depths = torch.empty(
            trajectory_length,
            self.num_envs,
            num_contacts_per_env,
            dtype=torch.float32,
            device=self.torch_device
        )
        contact_points_0 = torch.empty(
            trajectory_length, 
            self.num_envs,
            num_contacts_per_env,
            3,
            dtype=torch.float32,
            device=self.torch_device
        )
        contact_points_1 = torch.empty(
            trajectory_length, 
            self.num_envs,
            num_contacts_per_env,
            3,
            dtype=torch.float32,
            device=self.torch_device
        )
        contact_thicknesses = torch.empty(
            trajectory_length,
            self.num_envs,
            num_contacts_per_env,
            dtype=torch.float32,
            device=self.torch_device
        )

        # allocate buffer for contact plane generation
        contact_points_0_world_batch = torch.empty(
            self.num_envs * num_contacts_per_env,
            3,
            dtype = torch.float32,
            device = self.torch_device
        )
        normals_batch = torch.empty(
            self.num_envs,
            3,
            dtype = torch.float32,
            device = self.torch_device
        )
        ds_batch = torch.empty(
            self.num_envs,
            dtype = torch.float32,
            device = self.torch_device
        )
        
        contact_thickness = self.env.abstract_contacts.contact_thickness
        
        self.env.set_env_mode('ground-truth')
        
        _eval_collisions = self.env.eval_collisions
        self.env.set_eval_collisions(False)

        if export_video:
            self.env.start_video_export(export_video_path)

        rounds = 0
        for _ in progress:
            rounds += 1

            # generate random initial states and joint_acts
            self.sampler.sample(
                batch_size = self.num_envs, 
                low = self.states_min,
                high = self.states_max,
                data = initial_states)
            self.sampler.sample(
                batch_size = self.num_envs * trajectory_length, 
                low = -self.joint_act_scale,
                high = self.joint_act_scale,
                data = joint_acts.view(-1, self.joint_act_dim)
            )
            
            if passive:
                joint_acts *= 0.

            # set initial states
            self.env.reset(initial_states = initial_states)

            """ Sample grounds (normal, d) -> dot(normal, x) = d """
            # Step 1: compute contact points 0 in world frame
            wp.launch(
                compute_contact_points_0_world,
                dim=self.num_envs * num_contacts_per_env,
                inputs=[
                    self.env.sim_states.body_q,
                    self.env.model.shape_body,
                    wp.from_torch(self.env.abstract_contacts.contact_shape0),
                    wp.from_torch(
                        self.env.abstract_contacts.contact_point0, 
                        dtype=wp.vec3
                    )
                ],
                outputs=[
                    wp.from_torch(contact_points_0_world_batch, dtype=wp.vec3)
                ]
            )
            
            # Step 2: sample a ground normal for each env
            self.sampler.sample(
                batch_size = self.num_envs, 
                low = -1.,
                high = 1.,
                data = normals_batch
            )
            normals_batch = torch.nn.functional.normalize(
                normals_batch,
                p = 2.0, 
                dim = -1
            )

            expanded_normals_batch = normals_batch.unsqueeze(1).repeat(
                1, num_contacts_per_env, 1
            )
            
            # Step 3: compute the d for the tangential contact case
            d_tangential = torch.min(torch.sum(
                                contact_points_0_world_batch.view(
                                    self.num_envs, num_contacts_per_env, 3
                                ) * expanded_normals_batch,
                                dim = -1
                            ), dim = -1).values
        
            # Step 4: sample a d for each env's plane at least contact_thickness 
            #         away from the lowest pendulum point, but not too far away
            root_pos = self.env.root_body_q[:, 0:3]
            d_root = torch.sum(root_pos * normals_batch, dim = -1)
            d_lower = d_root - 3.5
            d_upper = d_tangential - contact_thickness[0]
            assert (d_upper >= d_lower).all()
            
            self.sampler.sample(
                batch_size = self.num_envs, 
                low = d_lower,
                high = d_upper,
                data = ds_batch
            )

            for step in range(trajectory_length):
                """ compute contact info """
                # compute contact points 0 in world frame
                wp.launch(
                    compute_contact_points_0_world,
                    dim=self.num_envs * num_contacts_per_env,
                    inputs=[
                        self.env.sim_states.body_q,
                        self.env.model.shape_body,
                        wp.from_torch(self.env.abstract_contacts.contact_shape0),
                        wp.from_torch(
                            self.env.abstract_contacts.contact_point0, 
                            dtype=wp.vec3
                        )
                    ],
                    outputs=[
                        wp.from_torch(contact_points_0_world_batch, dtype=wp.vec3)
                    ]
                )
                
                # compute contact_depths
                contact_depths[step, :, :] = (
                    contact_points_0_world_batch.view(
                        self.num_envs, num_contacts_per_env, 3
                    ) * expanded_normals_batch
                ).sum(-1) - ds_batch.unsqueeze(-1)
                
                # calculate contact point1 and set abstract contact configurations
                self.env.abstract_contacts.contact_normal[...] = expanded_normals_batch.view(-1, 3)
                self.env.abstract_contacts.contact_depth[...] = contact_depths[step, :, :].view(-1)
                
                wp.launch(
                    compute_contact_points_1,
                    dim=self.num_envs * num_contacts_per_env,
                    inputs=[
                        self.env.sim_states.body_q,
                        self.env.model.shape_body,
                        wp.from_torch(self.env.abstract_contacts.contact_shape0),
                        wp.from_torch(self.env.abstract_contacts.contact_point0, dtype=wp.vec3),
                        wp.from_torch(self.env.abstract_contacts.contact_normal, dtype=wp.vec3),
                        wp.from_torch(self.env.abstract_contacts.contact_depth)
                    ],
                    outputs=[
                        wp.from_torch(self.env.abstract_contacts.contact_point1, dtype=wp.vec3)
                    ],
                    device=self.env.device
                )
                
                # save contact point 0 (local link frame) to the created buffer
                contact_points_0[step, ...] = self.env.abstract_contacts.contact_point0.view(
                    self.num_envs,
                    num_contacts_per_env,
                    3,
                ).clone()
                
                # save contact point 1 (world frame) to created buffer
                contact_points_1[step, ...] = \
                    self.env.abstract_contacts.contact_point1.view(
                        self.num_envs, 
                        num_contacts_per_env, 
                        3
                    ).clone()
                        
                # save contact thickness to created buffer
                contact_thicknesses[step, ...] = \
                    self.env.abstract_contacts.contact_thickness.view(
                        self.num_envs, 
                        num_contacts_per_env
                    ).clone()

                # save contact normals
                contact_normals[step, ...] = expanded_normals_batch.clone()
                
                if render:
                    self.env.render()

                root_body_q[step, :, :].copy_(self.env.root_body_q)
                states[step, :, :].copy_(self.env.states)
                next_states[step, :, :].copy_(
                    self.env.step_with_joint_act(
                        joint_acts[step, :, :],
                        env_mode = 'ground-truth'
                    )
                )

            # print(contact_depths.min())
            # save to trajectories
            rollout_batches['gravity_dir'].append(gravity_dir.clone())
            rollout_batches['root_body_q'].append(root_body_q.clone())
            rollout_batches['states'].append(states.clone())
            rollout_batches['contacts']['contact_normals'].append(contact_normals.clone())
            rollout_batches['contacts']['contact_depths'].append(contact_depths.clone())
            rollout_batches['contacts']['contact_points_0'].append(contact_points_0.clone())
            rollout_batches['contacts']['contact_points_1'].append(contact_points_1.clone())
            rollout_batches['contacts']['contact_thicknesses'].append(contact_thicknesses.clone())
            rollout_batches['joint_acts'].append(joint_acts.clone())
            rollout_batches['next_states'].append(next_states.clone())

        print(f'\n\nTotal number of transitions generated: {rounds * self.num_envs * trajectory_length}')

        # merge rollout batches
        rollouts = {}
        for key in rollout_batches:
            if isinstance(rollout_batches[key], dict):
                rollouts[key] = {}
                for sub_key in rollout_batches[key]:
                    rollouts[key][sub_key] = torch.cat(rollout_batches[key][sub_key], dim = 1)
            else:
                rollouts[key] = torch.cat(rollout_batches[key], dim = 1)

        print('[DEBUG] sum(next_states) = ', rollouts['next_states'].sum())
        
        self.env.set_eval_collisions(_eval_collisions)
        
        if export_video:
            self.env.end_video_export()

        return rollouts